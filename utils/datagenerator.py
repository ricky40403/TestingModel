############################################################
#  Data Generator
############################################################

import numpy as np
import random
import scipy.misc
import scipy.ndimage

def resize_image(image, min_dim=None, max_dim=None, padding=False):
    """
    Resizes an image keeping the aspect ratio.

    min_dim: if provided, resizes the image such that it's smaller
        dimension == min_dim
    max_dim: if provided, ensures that the image longest side doesn't
        exceed this value.
    padding: If true, pads image with zeros so it's size is max_dim x max_dim

    Returns:
    image: the resized image
    window: (y1, x1, y2, x2). If max_dim is provided, padding might
        be inserted in the returned image. If so, this window is the
        coordinates of the image part of the full image (excluding
        the padding). The x2, y2 pixels are not included.
    scale: The scale factor used to resize the image
    padding: Padding added to the image [(top, bottom), (left, right), (0, 0)]
    """
    # Default window (y1, x1, y2, x2) and default scale == 1.
    h, w = image.shape[:2]
    window = (0, 0, h, w)
    scale = 1

    # Scale?
    if min_dim:
        # Scale up but not down
        scale = max(1, min_dim / min(h, w))
    # Does it exceed max dim?
    if max_dim:
        image_max = max(h, w)
        if round(image_max * scale) > max_dim:
            scale = max_dim / image_max
    # Resize image and mask
    if scale != 1:
        image = scipy.misc.imresize(
            image, (round(h * scale), round(w * scale)))
    # Need padding?
    if padding:
        # Get new height and width
        h, w = image.shape[:2]
        top_pad = (max_dim - h) // 2
        bottom_pad = max_dim - h - top_pad
        left_pad = (max_dim - w) // 2
        right_pad = max_dim - w - left_pad
        padding = [(top_pad, bottom_pad), (left_pad, right_pad), (0, 0)]
        image = np.pad(image, padding, mode='constant', constant_values=0)
        window = (top_pad, left_pad, h + top_pad, w + left_pad)
    return image, window, scale, padding


def resize_mask(mask, scale, padding):
    """Resizes a mask using the given scale and padding.
    Typically, you get the scale and padding from resize_image() to
    ensure both, the image and the mask, are resized consistently.

    scale: mask scaling factor
    padding: Padding to add to the mask in the form
            [(top, bottom), (left, right), (0, 0)]
    """
    h, w = mask.shape[:2]
    mask = scipy.ndimage.zoom(mask, zoom=[scale, scale, 1], order=0)
    mask = np.pad(mask, padding, mode='constant', constant_values=0)
    return mask

def mold_image(images, config):
    """Takes RGB images with 0-255 values and subtraces
    the mean pixel and converts it to float. Expects image
    colors in RGB order.
    """
    return images.astype(np.float32) - config.MEAN_PIXEL



def load_image_gt(dataset, config, image_id, augment=False,use_mini_mask=False,use_background = False):

    """Load and return ground truth data for an image .
    dataset : Using uitls.dataset
    augment: If true, apply random image augmentation. Currently, only
        horizontal flipping is offered.
    use_mini_mask: If False, returns full-size masks that are the same height
        and width as the original image. These can be big, for example
        1024x1024x100 (for 100 instances). Mini masks are smaller, typically,
        224x224 and are generated by extracting the bounding box of the
        object and resizing it to MINI_MASK_SHAPE.

    Returns:
    image: [height, width, 3]
    class_ids: [instance_count] Integer class IDs
    mask: [height, width, class_num]. The height and width are those
        of the image unless use_mini_mask is True, in which case they are
        defined in MINI_MASK_SHAPE.
    """

    # Load image and mask
    image = dataset.load_image(image_id)
    mask, class_ids = dataset.load_mask(image_id)
    shape = image.shape
    image, window, scale, padding = resize_image(
        image,
        min_dim=config.IMAGE_MIN_DIM,
        max_dim=config.IMAGE_MAX_DIM,
        padding=config.IMAGE_PADDING)
    mask = resize_mask(mask, scale, padding)
    
    class_num = dataset.num_classes
#     if use_background :
#         class_num = class_num + 1

    # Random horizontal flips.
    if augment:
        if random.randint(0, 1):
            image = np.fliplr(image)
            mask = np.fliplr(mask)

    #if mini_mask resize mask size
    # init ground_true_mask

    if use_mini_mask:
        y_mask = np.zeros(config.MINI_MASK_SHAPE+(class_num,))
        y_all_mask = np.zeros(config.MINI_MASK_SHAPE)
    else:
        y_mask = np.zeros((shape[0],shape[1],class_num))
        y_all_mask = np.zeros((shape[0],shape[1]))


    for i in range(0,class_ids.shape[0]):
        tmp = mask[:,:,i]
        if use_mini_mask:
            tmp = scipy.misc.imresize(tmp, config.MINI_MASK_SHAPE)

        y_mask[:,:,class_ids[i]] = np.logical_or(y_mask[:,:,class_ids[i]],tmp)
        y_all_mask = y_all_mask + tmp
    
    #generate background
    #in CoCo Background is class 0
    if use_background :
        background_mask = np.zeros(config.MINI_MASK_SHAPE)
        #resize mask
        if use_mini_mask:
            background_mask = scipy.misc.imresize(background_mask, config.MINI_MASK_SHAPE)

        for i in range(0,mask.shape[2]):
            tmp = mask[:,:,i]
            # resize mask
            if use_mini_mask:
                tmp = scipy.misc.imresize(tmp, config.MINI_MASK_SHAPE)
            background_mask = np.logical_or(background_mask,tmp)

        # xor 
        background_mask = np.logical_xor(background_mask,1)

        y_mask[:,:,0] = background_mask
    
    return image, class_ids, y_mask.astype(float), y_all_mask.astype(float)



def data_generator(dataset, config, shuffle=True, augment=True, random_rois=0,
                   batch_size=1, detection_targets=False,use_background=True):
    b = 0  # batch item index
    image_index = -1
    image_ids = np.copy(dataset.image_ids)
    error_count = 0
    class_num = dataset.num_classes
    while True:
        try:
            # Increment index to pick next image. Shuffle if at the start of an epoch.
            image_index = (image_index + 1) % len(image_ids)
            if shuffle and image_index == 0:
                np.random.shuffle(image_ids)
            
            # Get GT bounding boxes and masks for image.
            image_id = image_ids[image_index]

            image, gt_class_ids, gt_masks, gt_masks_all_mask = \
                load_image_gt(dataset, config, image_id, augment=augment,
                          use_mini_mask=config.USE_MINI_MASK,use_background=use_background)
                
            # Skip images that have no instances. This can happen in cases
            # where we train on a subset of classes and the image doesn't
            # have any of the classes we care about.
            if not np.any(gt_class_ids > 0):
                continue
                
            # Init batch arrays
            if b == 0:
                batch_images = np.zeros(
                    (batch_size,) + image.shape, dtype=np.float32)
                batch_gt_class_ids = np.zeros(
                    (batch_size, config.MAX_GT_INSTANCES), dtype=np.int32)
                
                if config.USE_MINI_MASK:
#                     batch_gt_masks = np.zeros((batch_size, config.MINI_MASK_SHAPE[0], config.MINI_MASK_SHAPE[1],
#                                                config.MAX_GT_INSTANCES))
#                     batch_gt_masks = np.zeros((batch_size, config.MINI_MASK_SHAPE[0], config.MINI_MASK_SHAPE[1], 1))

                    #set to (shape*shape,2) 
                    #object and background
                    batch_gt_masks = np.zeros((batch_size, config.MINI_MASK_SHAPE[0] * config.MINI_MASK_SHAPE[1], class_num))
    
                else:
#                     batch_gt_masks = np.zeros(
#                         (batch_size, image.shape[0], image.shape[1], config.MAX_GT_INSTANCES))
#                     batch_gt_masks = np.zeros(
#                         (batch_size, image.shape[0], image.shape[1], 1))
                    batch_gt_masks = np.zeros(
                        (batch_size, image.shape[0] * image.shape[1], class_num))
                    
                # If more instances than fits in the array, sub-sample from them.
#             if gt_boxes.shape[0] > config.MAX_GT_INSTANCES:
#                 ids = np.random.choice(
#                     np.arange(gt_boxes.shape[0]), config.MAX_GT_INSTANCES, replace=False)
#                 gt_class_ids = gt_class_ids[ids]
#                 gt_boxes = gt_boxes[ids]
#                 gt_masks = gt_masks[:, :, ids]

            # Add to batch
#             batch_image_meta[b] = image_meta
#             batch_rpn_match[b] = rpn_match[:, np.newaxis]
#             batch_rpn_bbox[b] = rpn_bbox
            batch_images[b] = mold_image(image.astype(np.float32), config)
            batch_gt_class_ids[b, :gt_class_ids.shape[0]] = gt_class_ids
#             batch_gt_boxes[b, :gt_boxes.shape[0]] = gt_boxes
#             batch_gt_masks[b, :, :, :gt_masks.shape[-1]] = gt_masks


            gt_masks = np.reshape(gt_masks,(56*56,class_num))
            #add to batch
            batch_gt_masks[0] = gt_masks.astype(float)
            
            if random_rois:
                batch_rpn_rois[b] = rpn_rois
                if detection_targets:
                    batch_rois[b] = rois
                    batch_mrcnn_class_ids[b] = mrcnn_class_ids
                    batch_mrcnn_bbox[b] = mrcnn_bbox
                    batch_mrcnn_mask[b] = mrcnn_mask
            b += 1

            # Batch full?
            inputs = batch_images
            outputs = batch_gt_masks
#                 inputs = [batch_images, batch_image_meta,
#                           batch_gt_class_ids, batch_gt_boxes, batch_gt_masks]
#                 outputs = []

#                 if random_rois:
#                     inputs.extend([batch_rpn_rois])
#                     if detection_targets:
#                         inputs.extend([batch_rois])
#                         # Keras requires that output and targets have the same number of dimensions
#                         batch_mrcnn_class_ids = np.expand_dims(
#                             batch_mrcnn_class_ids, -1)
#                         outputs.extend(
#                             [batch_mrcnn_class_ids, batch_mrcnn_bbox, batch_mrcnn_mask])


            yield inputs, outputs

                # start a new batch
            b = 0
        except (GeneratorExit, KeyboardInterrupt):
            raise
        except:
            # Log it and skip the image
            logging.exception("Error processing image {}".format(
                dataset.image_info[image_id]))
            error_count += 1
            if error_count > 5:
                raise