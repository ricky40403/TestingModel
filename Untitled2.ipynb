{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# from utils import datagenerator\n",
    "from utils.shape import ShapesConfig\n",
    "from coco import CocoDataset\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.Data_Generator import data_generator, PASCAL_ImageSetLoader\n",
    "import yaml\n",
    "from keras.applications.imagenet_utils import _obtain_input_shape\n",
    "from keras import backend as K\n",
    "import keras.layers as KL\n",
    "import keras.models as KM\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "from utils.BilinearUpSampling import *\n",
    "from utils.Mylayers import *\n",
    "from utils.model import *\n",
    "from utils.crfrnn_layer import *\n",
    "import keras\n",
    "from utils.Data_Generator import load_image_gt\n",
    "# import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations:\n",
      "BACKBONE_SHAPES                [[56 56]\n",
      " [28 28]\n",
      " [14 14]\n",
      " [ 7  7]\n",
      " [ 4  4]]\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     8\n",
      "BBOX_STD_DEV                   [ 0.1  0.1  0.2  0.2]\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.7\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "GPU_COUNT                      1\n",
      "IMAGES_PER_GPU                 8\n",
      "IMAGE_MAX_DIM                  224\n",
      "IMAGE_MIN_DIM                  224\n",
      "IMAGE_PADDING                  True\n",
      "IMAGE_SHAPE                    [224 224   3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.002\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [ 123.7  116.8  103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           shapes\n",
      "NUM_CLASSES                    4\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (8, 16, 32, 64, 128)\n",
      "RPN_ANCHOR_STRIDE              2\n",
      "RPN_BBOX_STD_DEV               [ 0.1  0.1  0.2  0.2]\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                100\n",
      "TRAIN_MODE                     MASK\n",
      "TRAIN_ROIS_PER_IMAGE           32\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               5\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "config = ShapesConfig()\n",
    "config.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.64s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "dataset_train = CocoDataset()\n",
    "dataset_train.load_coco('coco_dataset/', \"val\")\n",
    "dataset_train.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.MINI_MASK_SHAPE = (224,224)\n",
    "config.RPN_TRAIN_ANCHORS_PER_IMAGE = 224*224\n",
    "# config.IMAGE_MIN_DIM = 800\n",
    "# config.IMAGE_MAX_DIM = 1024\n",
    "config.BATCH_SIZE = 8\n",
    "config.IMAGE_META_SIZE = 1 + 3 + 3 + 4 + 1 + 81"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Batch Slicing\n",
    "# Some custom layers support a batch size of 1 only, and require a lot of work\n",
    "# to support batches greater than 1. This function slices an input tensor\n",
    "# across the batch dimension and feeds batches of size 1. Effectively,\n",
    "# an easy way to support batches > 1 quickly with little code modification.\n",
    "# In the long run, it's more efficient to modify the code to support large\n",
    "# batches and getting rid of this function. Consider this a temporary solution\n",
    "def batch_slice(inputs, graph_fn, batch_size, names=None):\n",
    "    \"\"\"Splits inputs into slices and feeds each slice to a copy of the given\n",
    "    computation graph and then combines the results. It allows you to run a\n",
    "    graph on a batch of inputs even if the graph is written to support one\n",
    "    instance only.\n",
    "    inputs: list of tensors. All must have the same first dimension length\n",
    "    graph_fn: A function that returns a TF tensor that's part of a graph.\n",
    "    batch_size: number of slices to divide the data into.\n",
    "    names: If provided, assigns names to the resulting tensors.\n",
    "    \"\"\"\n",
    "    if not isinstance(inputs, list):\n",
    "        inputs = [inputs]\n",
    "\n",
    "    outputs = []\n",
    "    for i in range(batch_size):\n",
    "        inputs_slice = [x[i] for x in inputs]\n",
    "        output_slice = graph_fn(*inputs_slice)\n",
    "        if not isinstance(output_slice, (tuple, list)):\n",
    "            output_slice = [output_slice]\n",
    "        outputs.append(output_slice)\n",
    "    # Change outputs from a list of slices where each is\n",
    "    # a list of outputs to a list of outputs and each has\n",
    "    # a list of slices\n",
    "    outputs = list(zip(*outputs))\n",
    "\n",
    "    if names is None:\n",
    "        names = [None] * len(outputs)\n",
    "\n",
    "    result = [tf.stack(o, axis=0, name=n)\n",
    "              for o, n in zip(outputs, names)]\n",
    "    if len(result) == 1:\n",
    "        result = result[0]\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_box_deltas_graph(boxes, deltas):\n",
    "    \"\"\"Applies the given deltas to the given boxes.\n",
    "    boxes: [N, (y1, x1, y2, x2)] boxes to update\n",
    "    deltas: [N, (dy, dx, log(dh), log(dw))] refinements to apply\n",
    "    \"\"\"\n",
    "    # Convert to y, x, h, w\n",
    "    height = boxes[:, 2] - boxes[:, 0]\n",
    "    width = boxes[:, 3] - boxes[:, 1]\n",
    "    center_y = boxes[:, 0] + 0.5 * height\n",
    "    center_x = boxes[:, 1] + 0.5 * width\n",
    "    # Apply deltas\n",
    "    center_y += deltas[:, 0] * height\n",
    "    center_x += deltas[:, 1] * width\n",
    "#     height *= tf.exp(deltas[:, 2])\n",
    "#     width *= tf.exp(deltas[:, 3])\n",
    "    # Convert back to y1, x1, y2, x2\n",
    "    y1 = center_y - 0.5 * height\n",
    "    x1 = center_x - 0.5 * width\n",
    "    y2 = y1 + height\n",
    "    x2 = x1 + width\n",
    "    result = tf.stack([y1, x1, y2, x2], axis=1, name=\"apply_box_deltas_out\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_anchors(scales, ratios, i):\n",
    "    \n",
    "    BACKBONE_SIZE = [56,28,14,7]\n",
    "    BACKBONE_STRIDES = [4, 8, 16, 32]\n",
    "    \n",
    "    # Get all combinations of scales and ratios\n",
    "    scales, ratios = np.meshgrid(np.array(scales), np.array(ratios))\n",
    "    scales = scales.flatten()\n",
    "    ratios = ratios.flatten()\n",
    "\n",
    "    # Enumerate heights and widths from scales and ratios\n",
    "    heights = scales / np.sqrt(ratios)\n",
    "    widths = scales * np.sqrt(ratios)\n",
    "\n",
    "    # Enumerate shifts in feature space\n",
    "    shifts_y = np.arange(0, BACKBONE_SIZE[i]) * BACKBONE_STRIDES[i]\n",
    "    shifts_x = np.arange(0, BACKBONE_SIZE[i]) * BACKBONE_STRIDES[i]\n",
    "    shifts_x, shifts_y = np.meshgrid(shifts_x, shifts_y)\n",
    "    \n",
    "    # Enumerate combinations of shifts, widths, and heights\n",
    "    box_widths, box_centers_x = np.meshgrid(widths, shifts_x)\n",
    "    box_heights, box_centers_y = np.meshgrid(heights, shifts_y)\n",
    "\n",
    "    # Reshape to get a list of (y, x) and a list of (h, w)\n",
    "    box_centers = np.stack(\n",
    "        [box_centers_y, box_centers_x], axis=2).reshape([-1, 2])\n",
    "    box_sizes = np.stack([box_heights, box_widths], axis=2).reshape([-1, 2])\n",
    "\n",
    "    # Convert to corner coordinates (y1, x1, y2, x2)\n",
    "    boxes = np.concatenate([box_centers - 0.5 * box_sizes,\n",
    "                            box_centers + 0.5 * box_sizes], axis=1)\n",
    "#     print(box_centers)\n",
    "    \n",
    "    return boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CroppingBoxLayer(keras.engine.Layer):\n",
    "    def __init__(self, pool_shape, anchors, **kwargs):\n",
    "        super(CroppingBoxLayer, self).__init__(**kwargs)\n",
    "        self.pool_shape = tuple(pool_shape)\n",
    "        self.box_num = 0\n",
    "        self.anchors = anchors\n",
    "#         self.feature_map = None\n",
    "        \n",
    "    def call(self, feature_map):\n",
    "      \n",
    "\n",
    "        # get batch\n",
    "        indice = tf.where(tf.equal(feature_map[:, 0, 0, 0], feature_map[:, 0, 0, 0]))\n",
    "        indice = tf.cast(indice[:,0], tf.float32)\n",
    "        # fit batch to number_boxes size\n",
    "        y1, x1, y2, x2 = tf.split(self.anchors, 4, axis = -1)\n",
    "        indice, y1 = tf.meshgrid(indice, y1)\n",
    "        indice = tf.cast(indice[:,0], tf.int32)\n",
    "    \n",
    "        print(\"CroppingBoxLayer anchors :{}\".format(self.anchors))\n",
    "        print(\"CroppingBoxLayer indice :{}\".format(indice))\n",
    "        pooled = tf.image.crop_and_resize(feature_map, self.anchors, indice, (16, 16), method=\"bilinear\")\n",
    "\n",
    "        # because the indice is in order , so just reshape\n",
    "        # reshape to [batch, num_boxes, 16, 16, 256]\n",
    "#         pooled = tf.reshape(pooled, (config.BATCH_SIZE, 224*224*15, pooled.shape[1], pooled.shape[2], pooled.shape[3]))\n",
    "        pooled = tf.expand_dims(pooled, 0)\n",
    "\n",
    "        return pooled   \n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (1,12495, 16,16,256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RefineAndCropLayer(keras.engine.Layer):\n",
    "    def __init__(self, config, anchors, feature_maps, **kwargs):\n",
    "        super(RefineAndCropLayer, self).__init__(**kwargs)\n",
    "        self.config = config\n",
    "        self.feature_map = feature_maps\n",
    "        self.anchors = anchors\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        \n",
    "        deltas = inputs[0]\n",
    "        gt_class_ids = inputs[1]\n",
    "        gt_boxes = inputs[2]\n",
    "        gt_masks = inputs[3]\n",
    "        \n",
    "        # extend anchor to batch size\n",
    "        boxes = tf.expand_dims(self.anchors, axis=0)\n",
    "        print(\"RefineAndCropLayer input boxes: {}\".format(boxes))\n",
    "        \n",
    "#         # Positive anchors contribute to the loss, but negative and\n",
    "#         # neutral anchors (match value of 0 or -1) don't.\n",
    "#         rpn_match = K.squeeze(rpn_match, -1)\n",
    "#         indices = tf.where(K.equal(rpn_match, 1))\n",
    "#         # Pick bbox deltas that contribute to the loss\n",
    "#         positive_bbox = tf.gather_nd(boxes, indices)\n",
    "#         positive_delta = tf.gather_nd(deltas, indices)\n",
    "#         self.output_box_num = K.int_shape(positive_bbox)[0]\n",
    "#         print(K.int_shape(positive_bbox))\n",
    "#         print(K.int_shape(positive_bbox)[0])\n",
    "#         print(K.int_shape(positive_bbox)[1])\n",
    "#         print(\"RefineAndCropLayer positive_bbox :{}\".format(positive_bbox))\n",
    "#         print(\"RefineAndCropLayer positive_delta :{}\".format(positive_delta))\n",
    "\n",
    "        \n",
    "#         positive_bbox = tf.expand_dims(positive_bbox, axis=0)\n",
    "#         positive_delta = tf.expand_dims(positive_delta, axis=0)\n",
    "#         s = K.int_shape(positive_bbox)\n",
    "#         print(s)\n",
    "#         s = K.int_shape(positive_delta)\n",
    "#         print(s)\n",
    "\n",
    "        proposals = batch_slice([boxes, deltas],                            \n",
    "                              lambda x, y: apply_box_deltas_graph(x, y),\n",
    "                              1,\n",
    "                              names=[\"refined_anchors\"])\n",
    "    \n",
    "        print(\"RefineAndCropLayer refined proposals: {}\".format(boxes))\n",
    "        \n",
    "        \n",
    "        # rois: [batch, TRAIN_ROIS_PER_IMAGE, (y1, x1, y2, x2)] in normalized coordinates\n",
    "        # target_class_ids: [batch, TRAIN_ROIS_PER_IMAGE]. Integer class IDs.\n",
    "        # target_deltas: [batch, TRAIN_ROIS_PER_IMAGE, NUM_CLASSES,\n",
    "        #           (dy, dx, log(dh), log(dw), class_id)]\n",
    "        #           Class-specific bbox refinements.\n",
    "        # target_mask: [batch, TRAIN_ROIS_PER_IMAGE, height, width)\n",
    "        #        Masks cropped to bbox boundaries and resized to neural\n",
    "        #        network output size.\n",
    "        # Slice the batch and run a graph for each slice\n",
    "        # TODO: Rename target_bbox to target_deltas for clarity\n",
    "        names = [\"rois\", \"target_class_ids\", \"target_bbox\", \"target_mask\"]\n",
    "        rois, target_class_ids, target_bbox, target_mask = batch_slice(\n",
    "            [proposals, gt_class_ids, gt_boxes, gt_masks],\n",
    "            lambda w, x, y, z: detection_targets_graph(\n",
    "                w, x, y, z, self.config),\n",
    "            1, names=names)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        print(rois)\n",
    "#         indices = tf.cast(indices[:,0], tf.int32)\n",
    "\n",
    "        # get batch\n",
    "        indice = tf.where(tf.equal(rois[:,0,0], rois[:,0,0]))\n",
    "#         print(indice)\n",
    "        indice = tf.cast(indice[:,0], tf.float32)\n",
    "        \n",
    "        # fit batch to number_boxes size\n",
    "        y1, x1, y2, x2 = tf.split(rois, 4, axis = -1)\n",
    "        indice, y1 = tf.meshgrid(indice, y1)\n",
    "        indice = tf.cast(indice[:,0], tf.int32)\n",
    "        rois = tf.squeeze(rois, axis=0)        \n",
    "        \n",
    "        print(\"RefineAndCropLayer rois :{}\".format(rois))\n",
    "        print(\"RefineAndCropLayer indice :{}\".format(indice))\n",
    "        \n",
    "        cropped = tf.image.crop_and_resize(self.feature_map, rois, indice, (16, 16), method=\"bilinear\")\n",
    "        cropped = tf.expand_dims(cropped, 0)\n",
    "        print(\"RefineAndCropLayer cropped :{}\".format(cropped))\n",
    "        \n",
    "        return [cropped, rois, target_class_ids, target_bbox, target_mask]\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "         return [\n",
    "            (None, self.config.TRAIN_ROIS_PER_IMAGE, 16, 16, 256), #cropped output\n",
    "            (None, self.config.TRAIN_ROIS_PER_IMAGE, 4),  # rois\n",
    "            (None, 1),  # class_ids\n",
    "            (None, self.config.TRAIN_ROIS_PER_IMAGE, 4),  # deltas\n",
    "            (None, self.config.TRAIN_ROIS_PER_IMAGE, self.config.MASK_SHAPE[0],\n",
    "             self.config.MASK_SHAPE[1])  # masks\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_l1_loss(y_true, y_pred):\n",
    "    \"\"\"Implements Smooth-L1 loss.\n",
    "    y_true and y_pred are typicallly: [N, 4], but could be any shape.\n",
    "    \"\"\"\n",
    "    diff = K.abs(y_true - y_pred)\n",
    "    less_than_one = K.cast(K.less(diff, 1.0), \"float32\")\n",
    "    loss = (less_than_one * 0.5 * diff**2) + (1 - less_than_one) * (diff - 0.5)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confidence_loss(rpn_match, rpn_class_logits):\n",
    "    \"\"\"RPN anchor classifier loss.\n",
    "    rpn_match: [batch, anchors, 1]. Anchor match type. 1=positive,\n",
    "               -1=negative, 0=neutral anchor.\n",
    "    rpn_class_logits: [batch, anchors, 2]. RPN classifier logits for FG/BG.\n",
    "    \"\"\"\n",
    "    # Squeeze last dim to simplify\n",
    "    rpn_match = tf.squeeze(rpn_match, -1)\n",
    "    # Get anchor classes. Convert the -1/+1 match to 0/1 values.\n",
    "    anchor_class = K.cast(K.equal(rpn_match, 1), tf.int32)\n",
    "    # Positive and Negative anchors contribute to the loss,\n",
    "    # but neutral anchors (match value = 0) don't.\n",
    "    indices = tf.where(K.not_equal(rpn_match, 0))\n",
    "    # Pick rows that contribute to the loss and filter out the rest.\n",
    "    rpn_class_logits = tf.gather_nd(rpn_class_logits, indices)\n",
    "    anchor_class = tf.gather_nd(anchor_class, indices)\n",
    "    # Crossentropy loss\n",
    "    loss = K.sparse_categorical_crossentropy(target=anchor_class,\n",
    "                                             output=rpn_class_logits,\n",
    "                                             from_logits=True)\n",
    "    loss = K.switch(tf.size(loss) > 0, K.mean(loss), tf.constant(0.0))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_pack_graph(x, counts, num_rows):\n",
    "    \"\"\"Picks different number of values from each row\n",
    "    in x depending on the values in counts.\n",
    "    \"\"\"\n",
    "    outputs = []\n",
    "    for i in range(num_rows):\n",
    "        outputs.append(x[i, :counts[i]])\n",
    "    return tf.concat(outputs, axis=0)\n",
    "\n",
    "def box_reg_loss(config, target_bbox, rpn_match, rpn_bbox):\n",
    "    \"\"\"Return the RPN bounding box loss graph.\n",
    "    config: the model config object.\n",
    "    target_bbox: [batch, max positive anchors, (dy, dx)].\n",
    "        Uses 0 padding to fill in unsed bbox deltas.\n",
    "    rpn_match: [batch, anchors, 1]. Anchor match type. 1=positive,\n",
    "               -1=negative, 0=neutral anchor.\n",
    "    rpn_bbox: [batch, anchors, (dy, dx)]\n",
    "    \"\"\"\n",
    "\n",
    "    # Positive anchors contribute to the loss, but negative and\n",
    "    # neutral anchors (match value of 0 or -1) don't.\n",
    "    rpn_match = K.squeeze(rpn_match, -1)\n",
    "    indices = tf.where(K.equal(rpn_match, 1))\n",
    "\n",
    "    # Pick bbox deltas that contribute to the loss\n",
    "    rpn_bbox = tf.gather_nd(rpn_bbox, indices)\n",
    "\n",
    "    # Trim target bounding box deltas to the same length as rpn_bbox.\n",
    "    batch_counts = K.sum(K.cast(K.equal(rpn_match, 1), tf.int32), axis=1)\n",
    "    target_bbox = batch_pack_graph(target_bbox, batch_counts,\n",
    "                                   1)\n",
    "\n",
    "    # TODO: use smooth_l1_loss() rather than reimplementing here\n",
    "    #       to reduce code duplication\n",
    "    diff = K.abs(target_bbox - rpn_bbox)\n",
    "    less_than_one = K.cast(K.less(diff, 1.0), \"float32\")\n",
    "    loss = (less_than_one * 0.5 * diff**2) + (1 - less_than_one) * (diff - 0.5)\n",
    "\n",
    "    loss = K.switch(tf.size(loss) > 0, K.mean(loss), tf.constant(0.0))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mrcnn_class_loss_graph(target_class_ids, pred_class_logits,\n",
    "                           active_class_ids):\n",
    "    \"\"\"Loss for the classifier head of Mask RCNN.\n",
    "    target_class_ids: [batch, num_rois]. Integer class IDs. Uses zero\n",
    "        padding to fill in the array.\n",
    "    pred_class_logits: [batch, num_rois, num_classes]\n",
    "    active_class_ids: [batch, num_classes]. Has a value of 1 for\n",
    "        classes that are in the dataset of the image, and 0\n",
    "        for classes that are not in the dataset.\n",
    "    \"\"\"\n",
    "    # During model building, Keras calls this function with\n",
    "    # target_class_ids of type float32. Unclear why. Cast it\n",
    "    # to int to get around it.\n",
    "    target_class_ids = tf.cast(target_class_ids, 'int64')\n",
    "\n",
    "    # Find predictions of classes that are not in the dataset.\n",
    "    pred_class_ids = tf.argmax(pred_class_logits, axis=2)\n",
    "    # TODO: Update this line to work with batch > 1. Right now it assumes all\n",
    "    #       images in a batch have the same active_class_ids\n",
    "    pred_active = tf.gather(active_class_ids[0], pred_class_ids)\n",
    "\n",
    "    # Loss\n",
    "    loss = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "        labels=target_class_ids, logits=pred_class_logits)\n",
    "\n",
    "    # Erase losses of predictions of classes that are not in the active\n",
    "    # classes of the image.\n",
    "    loss = loss * pred_active\n",
    "\n",
    "    # Computer loss mean. Use only predictions that contribute\n",
    "    # to the loss to get a correct mean.\n",
    "    loss = tf.reduce_sum(loss) / tf.reduce_sum(pred_active)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def mrcnn_bbox_loss_graph(target_bbox, target_class_ids, pred_bbox):\n",
    "    \"\"\"Loss for Mask R-CNN bounding box refinement.\n",
    "    target_bbox: [batch, num_rois, (dy, dx, log(dh), log(dw))]\n",
    "    target_class_ids: [batch, num_rois]. Integer class IDs.\n",
    "    pred_bbox: [batch, num_rois, num_classes, (dy, dx, log(dh), log(dw))]\n",
    "    \"\"\"\n",
    "    # Reshape to merge batch and roi dimensions for simplicity.\n",
    "    target_class_ids = K.reshape(target_class_ids, (-1,))\n",
    "    target_bbox = K.reshape(target_bbox, (-1, 4))\n",
    "    pred_bbox = K.reshape(pred_bbox, (-1, K.int_shape(pred_bbox)[2], 4))\n",
    "\n",
    "    # Only positive ROIs contribute to the loss. And only\n",
    "    # the right class_id of each ROI. Get their indicies.\n",
    "    positive_roi_ix = tf.where(target_class_ids > 0)[:, 0]\n",
    "    positive_roi_class_ids = tf.cast(\n",
    "        tf.gather(target_class_ids, positive_roi_ix), tf.int64)\n",
    "    indices = tf.stack([positive_roi_ix, positive_roi_class_ids], axis=1)\n",
    "\n",
    "    # Gather the deltas (predicted and true) that contribute to loss\n",
    "    target_bbox = tf.gather(target_bbox, positive_roi_ix)\n",
    "    pred_bbox = tf.gather_nd(pred_bbox, indices)\n",
    "\n",
    "    # Smooth-L1 Loss\n",
    "    loss = K.switch(tf.size(target_bbox) > 0,\n",
    "                    smooth_l1_loss(y_true=target_bbox, y_pred=pred_bbox),\n",
    "                    tf.constant(0.0))\n",
    "    loss = K.mean(loss)\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DetectionTargetLayer(keras.engine.Layer):\n",
    "    \"\"\"Subsamples proposals and generates target box refinement, class_ids,\n",
    "    and masks for each.\n",
    "    Inputs:\n",
    "    proposals: [batch, N, (y1, x1, y2, x2)] in normalized coordinates. Might\n",
    "               be zero padded if there are not enough proposals.\n",
    "    gt_class_ids: [batch, MAX_GT_INSTANCES] Integer class IDs.\n",
    "    gt_boxes: [batch, MAX_GT_INSTANCES, (y1, x1, y2, x2)] in normalized\n",
    "              coordinates.\n",
    "    gt_masks: [batch, height, width, MAX_GT_INSTANCES] of boolean type\n",
    "    Returns: Target ROIs and corresponding class IDs, bounding box shifts,\n",
    "    and masks.\n",
    "    rois: [batch, TRAIN_ROIS_PER_IMAGE, (y1, x1, y2, x2)] in normalized\n",
    "          coordinates\n",
    "    target_class_ids: [batch, TRAIN_ROIS_PER_IMAGE]. Integer class IDs.\n",
    "    target_deltas: [batch, TRAIN_ROIS_PER_IMAGE, NUM_CLASSES,\n",
    "                    (dy, dx, log(dh), log(dw), class_id)]\n",
    "                   Class-specific bbox refinements.\n",
    "    target_mask: [batch, TRAIN_ROIS_PER_IMAGE, height, width)\n",
    "                 Masks cropped to bbox boundaries and resized to neural\n",
    "                 network output size.\n",
    "    Note: Returned arrays might be zero padded if not enough target ROIs.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config, **kwargs):\n",
    "        super(DetectionTargetLayer, self).__init__(**kwargs)\n",
    "        self.config = config\n",
    "\n",
    "    def call(self, inputs):\n",
    "        proposals = inputs[0]\n",
    "        gt_class_ids = inputs[1]\n",
    "        gt_boxes = inputs[2]\n",
    "        gt_masks = inputs[3]\n",
    "\n",
    "        # Slice the batch and run a graph for each slice\n",
    "        # TODO: Rename target_bbox to target_deltas for clarity\n",
    "        names = [\"rois\", \"target_class_ids\", \"target_bbox\", \"target_mask\"]\n",
    "        outputs = batch_slice(\n",
    "            [proposals, gt_class_ids, gt_boxes, gt_masks],\n",
    "            lambda w, x, y, z: detection_targets_graph(\n",
    "                w, x, y, z, self.config),\n",
    "            1, names=names)\n",
    "        return outputs\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return [\n",
    "            (None, self.config.TRAIN_ROIS_PER_IMAGE, 4),  # rois\n",
    "            (None, 1),  # class_ids\n",
    "            (None, self.config.TRAIN_ROIS_PER_IMAGE, 4),  # deltas\n",
    "            (None, self.config.TRAIN_ROIS_PER_IMAGE, self.config.MASK_SHAPE[0],\n",
    "             self.config.MASK_SHAPE[1])  # masks\n",
    "        ]\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        return [None, None, None, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_boxes_graph(boxes, shape):\n",
    "    \"\"\"Converts boxes from pixel coordinates to normalized coordinates.\n",
    "    boxes: [..., (y1, x1, y2, x2)] in pixel coordinates\n",
    "    shape: [..., (height, width)] in pixels\n",
    "    Note: In pixel coordinates (y2, x2) is outside the box. But in normalized\n",
    "    coordinates it's inside the box.\n",
    "    Returns:\n",
    "        [..., (y1, x1, y2, x2)] in normalized coordinates\n",
    "    \"\"\"\n",
    "    h, w = tf.split(tf.cast(shape, tf.float32), 2)\n",
    "    scale = tf.concat([h, w, h, w], axis=-1) - tf.constant(1.0)\n",
    "    shift = tf.constant([0., 0., 1., 1.])\n",
    "    return tf.divide(boxes - shift, scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_zeros_graph(boxes, name=None):\n",
    "    \"\"\"Often boxes are represented with matricies of shape [N, 4] and\n",
    "    are padded with zeros. This removes zero boxes.\n",
    "    boxes: [N, 4] matrix of boxes.\n",
    "    non_zeros: [N] a 1D boolean mask identifying the rows to keep\n",
    "    \"\"\"\n",
    "    non_zeros = tf.cast(tf.reduce_sum(tf.abs(boxes), axis=1), tf.bool)\n",
    "    boxes = tf.boolean_mask(boxes, non_zeros, name=name)\n",
    "    return boxes, non_zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def box_refinement_graph(box, gt_box):\n",
    "    \"\"\"Compute refinement needed to transform box to gt_box.\n",
    "    box and gt_box are [N, (y1, x1, y2, x2)]\n",
    "    \"\"\"\n",
    "    box = tf.cast(box, tf.float32)\n",
    "    gt_box = tf.cast(gt_box, tf.float32)\n",
    "\n",
    "    height = box[:, 2] - box[:, 0]\n",
    "    width = box[:, 3] - box[:, 1]\n",
    "    center_y = box[:, 0] + 0.5 * height\n",
    "    center_x = box[:, 1] + 0.5 * width\n",
    "\n",
    "    gt_height = gt_box[:, 2] - gt_box[:, 0]\n",
    "    gt_width = gt_box[:, 3] - gt_box[:, 1]\n",
    "    gt_center_y = gt_box[:, 0] + 0.5 * gt_height\n",
    "    gt_center_x = gt_box[:, 1] + 0.5 * gt_width\n",
    "\n",
    "    dy = (gt_center_y - center_y) / height\n",
    "    dx = (gt_center_x - center_x) / width\n",
    "    dh = tf.log(gt_height / height)\n",
    "    dw = tf.log(gt_width / width)\n",
    "\n",
    "    result = tf.stack([dy, dx, dh, dw], axis=1)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlaps_graph(boxes1, boxes2):\n",
    "    \"\"\"Computes IoU overlaps between two sets of boxes.\n",
    "    boxes1, boxes2: [N, (y1, x1, y2, x2)].\n",
    "    \"\"\"\n",
    "    # 1. Tile boxes2 and repeate boxes1. This allows us to compare\n",
    "    # every boxes1 against every boxes2 without loops.\n",
    "    # TF doesn't have an equivalent to np.repeate() so simulate it\n",
    "    # using tf.tile() and tf.reshape.\n",
    "    b1 = tf.reshape(tf.tile(tf.expand_dims(boxes1, 1),\n",
    "                            [1, 1, tf.shape(boxes2)[0]]), [-1, 4])\n",
    "    b2 = tf.tile(boxes2, [tf.shape(boxes1)[0], 1])\n",
    "    # 2. Compute intersections\n",
    "    b1_y1, b1_x1, b1_y2, b1_x2 = tf.split(b1, 4, axis=1)\n",
    "    b2_y1, b2_x1, b2_y2, b2_x2 = tf.split(b2, 4, axis=1)\n",
    "    y1 = tf.maximum(b1_y1, b2_y1)\n",
    "    x1 = tf.maximum(b1_x1, b2_x1)\n",
    "    y2 = tf.minimum(b1_y2, b2_y2)\n",
    "    x2 = tf.minimum(b1_x2, b2_x2)\n",
    "    intersection = tf.maximum(x2 - x1, 0) * tf.maximum(y2 - y1, 0)\n",
    "    # 3. Compute unions\n",
    "    b1_area = (b1_y2 - b1_y1) * (b1_x2 - b1_x1)\n",
    "    b2_area = (b2_y2 - b2_y1) * (b2_x2 - b2_x1)\n",
    "    union = b1_area + b2_area - intersection\n",
    "    # 4. Compute IoU and reshape to [boxes1, boxes2]\n",
    "    iou = intersection / union\n",
    "    overlaps = tf.reshape(iou, [tf.shape(boxes1)[0], tf.shape(boxes2)[0]])\n",
    "    return overlaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_image_meta_graph(meta):\n",
    "    \"\"\"Parses a tensor that contains image attributes to its components.\n",
    "    See compose_image_meta() for more details.\n",
    "    meta: [batch, meta length] where meta length depends on NUM_CLASSES\n",
    "    Returns a dict of the parsed tensors.\n",
    "    \"\"\"\n",
    "    image_id = meta[:, 0]\n",
    "    original_image_shape = meta[:, 1:4]\n",
    "    image_shape = meta[:, 4:7]\n",
    "    window = meta[:, 7:11]  # (y1, x1, y2, x2) window of image in in pixels\n",
    "    scale = meta[:, 11]\n",
    "    active_class_ids = meta[:, 12:]\n",
    "    return {\n",
    "        \"image_id\": image_id,\n",
    "        \"original_image_shape\": original_image_shape,\n",
    "        \"image_shape\": image_shape,\n",
    "        \"window\": window,\n",
    "        \"scale\": scale,\n",
    "        \"active_class_ids\": active_class_ids,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detection_targets_graph(proposals, gt_class_ids, gt_boxes, gt_masks, config):\n",
    "    \"\"\"Generates detection targets for one image. Subsamples proposals and\n",
    "    generates target class IDs, bounding box deltas, and masks for each.\n",
    "    Inputs:\n",
    "    proposals: [N, (y1, x1, y2, x2)] in normalized coordinates. Might\n",
    "               be zero padded if there are not enough proposals.\n",
    "    gt_class_ids: [MAX_GT_INSTANCES] int class IDs\n",
    "    gt_boxes: [MAX_GT_INSTANCES, (y1, x1, y2, x2)] in normalized coordinates.\n",
    "    gt_masks: [height, width, MAX_GT_INSTANCES] of boolean type.\n",
    "    Returns: Target ROIs and corresponding class IDs, bounding box shifts,\n",
    "    and masks.\n",
    "    rois: [TRAIN_ROIS_PER_IMAGE, (y1, x1, y2, x2)] in normalized coordinates\n",
    "    class_ids: [TRAIN_ROIS_PER_IMAGE]. Integer class IDs. Zero padded.\n",
    "    deltas: [TRAIN_ROIS_PER_IMAGE, NUM_CLASSES, (dy, dx, log(dh), log(dw))]\n",
    "            Class-specific bbox refinements.\n",
    "    masks: [TRAIN_ROIS_PER_IMAGE, height, width). Masks cropped to bbox\n",
    "           boundaries and resized to neural network output size.\n",
    "    Note: Returned arrays might be zero padded if not enough target ROIs.\n",
    "    \"\"\"\n",
    "    # Assertions\n",
    "    asserts = [\n",
    "        tf.Assert(tf.greater(tf.shape(proposals)[0], 0), [proposals],\n",
    "                  name=\"roi_assertion\"),\n",
    "    ]\n",
    "    with tf.control_dependencies(asserts):\n",
    "        proposals = tf.identity(proposals)\n",
    "\n",
    "    # Remove zero padding\n",
    "    proposals, _ = trim_zeros_graph(proposals, name=\"trim_proposals\")\n",
    "    gt_boxes, non_zeros = trim_zeros_graph(gt_boxes, name=\"trim_gt_boxes\")\n",
    "    gt_class_ids = tf.boolean_mask(gt_class_ids, non_zeros,\n",
    "                                   name=\"trim_gt_class_ids\")\n",
    "    gt_masks = tf.gather(gt_masks, tf.where(non_zeros)[:, 0], axis=2,\n",
    "                         name=\"trim_gt_masks\")\n",
    "\n",
    "    # Handle COCO crowds\n",
    "    # A crowd box in COCO is a bounding box around several instances. Exclude\n",
    "    # them from training. A crowd box is given a negative class ID.\n",
    "    crowd_ix = tf.where(gt_class_ids < 0)[:, 0]\n",
    "    non_crowd_ix = tf.where(gt_class_ids > 0)[:, 0]\n",
    "    crowd_boxes = tf.gather(gt_boxes, crowd_ix)\n",
    "    crowd_masks = tf.gather(gt_masks, crowd_ix, axis=2)\n",
    "    gt_class_ids = tf.gather(gt_class_ids, non_crowd_ix)\n",
    "    gt_boxes = tf.gather(gt_boxes, non_crowd_ix)\n",
    "    gt_masks = tf.gather(gt_masks, non_crowd_ix, axis=2)\n",
    "\n",
    "    # Compute overlaps matrix [proposals, gt_boxes]\n",
    "    overlaps = overlaps_graph(proposals, gt_boxes)\n",
    "\n",
    "    # Compute overlaps with crowd boxes [anchors, crowds]\n",
    "    crowd_overlaps = overlaps_graph(proposals, crowd_boxes)\n",
    "    crowd_iou_max = tf.reduce_max(crowd_overlaps, axis=1)\n",
    "    no_crowd_bool = (crowd_iou_max < 0.001)\n",
    "\n",
    "    # Determine postive and negative ROIs\n",
    "    roi_iou_max = tf.reduce_max(overlaps, axis=1)\n",
    "    # 1. Positive ROIs are those with >= 0.5 IoU with a GT box\n",
    "    positive_roi_bool = (roi_iou_max >= 0.5)\n",
    "    positive_indices = tf.where(positive_roi_bool)[:, 0]\n",
    "    # 2. Negative ROIs are those with < 0.5 with every GT box. Skip crowds.\n",
    "    negative_indices = tf.where(tf.logical_and(roi_iou_max < 0.5, no_crowd_bool))[:, 0]\n",
    "\n",
    "    # Subsample ROIs. Aim for 33% positive\n",
    "    # Positive ROIs\n",
    "    positive_count = int(config.TRAIN_ROIS_PER_IMAGE *\n",
    "                         config.ROI_POSITIVE_RATIO)\n",
    "    positive_indices = tf.random_shuffle(positive_indices)[:positive_count]\n",
    "    positive_count = tf.shape(positive_indices)[0]\n",
    "    # Negative ROIs. Add enough to maintain positive:negative ratio.\n",
    "    r = 1.0 / config.ROI_POSITIVE_RATIO\n",
    "    negative_count = tf.cast(r * tf.cast(positive_count, tf.float32), tf.int32) - positive_count\n",
    "    negative_indices = tf.random_shuffle(negative_indices)[:negative_count]\n",
    "    # Gather selected ROIs\n",
    "    positive_rois = tf.gather(proposals, positive_indices)\n",
    "    negative_rois = tf.gather(proposals, negative_indices)\n",
    "\n",
    "    # Assign positive ROIs to GT boxes.\n",
    "    positive_overlaps = tf.gather(overlaps, positive_indices)\n",
    "    roi_gt_box_assignment = tf.argmax(positive_overlaps, axis=1)\n",
    "    roi_gt_boxes = tf.gather(gt_boxes, roi_gt_box_assignment)\n",
    "    roi_gt_class_ids = tf.gather(gt_class_ids, roi_gt_box_assignment)\n",
    "\n",
    "    # Compute bbox refinement for positive ROIs\n",
    "    deltas = box_refinement_graph(positive_rois, roi_gt_boxes)\n",
    "    deltas /= config.BBOX_STD_DEV\n",
    "\n",
    "    # Assign positive ROIs to GT masks\n",
    "    # Permute masks to [N, height, width, 1]\n",
    "    transposed_masks = tf.expand_dims(tf.transpose(gt_masks, [2, 0, 1]), -1)\n",
    "    # Pick the right mask for each ROI\n",
    "    roi_masks = tf.gather(transposed_masks, roi_gt_box_assignment)\n",
    "\n",
    "    # Compute mask targets\n",
    "    boxes = positive_rois\n",
    "    if config.USE_MINI_MASK:\n",
    "        # Transform ROI corrdinates from normalized image space\n",
    "        # to normalized mini-mask space.\n",
    "        y1, x1, y2, x2 = tf.split(positive_rois, 4, axis=1)\n",
    "        gt_y1, gt_x1, gt_y2, gt_x2 = tf.split(roi_gt_boxes, 4, axis=1)\n",
    "        gt_h = gt_y2 - gt_y1\n",
    "        gt_w = gt_x2 - gt_x1\n",
    "        y1 = (y1 - gt_y1) / gt_h\n",
    "        x1 = (x1 - gt_x1) / gt_w\n",
    "        y2 = (y2 - gt_y1) / gt_h\n",
    "        x2 = (x2 - gt_x1) / gt_w\n",
    "        boxes = tf.concat([y1, x1, y2, x2], 1)\n",
    "    box_ids = tf.range(0, tf.shape(roi_masks)[0])\n",
    "    masks = tf.image.crop_and_resize(tf.cast(roi_masks, tf.float32), boxes,\n",
    "                                     box_ids,\n",
    "                                     config.MASK_SHAPE)\n",
    "    # Remove the extra dimension from masks.\n",
    "    masks = tf.squeeze(masks, axis=3)\n",
    "\n",
    "    # Threshold mask pixels at 0.5 to have GT masks be 0 or 1 to use with\n",
    "    # binary cross entropy loss.\n",
    "    masks = tf.round(masks)\n",
    "\n",
    "    # Append negative ROIs and pad bbox deltas and masks that\n",
    "    # are not used for negative ROIs with zeros.\n",
    "    rois = tf.concat([positive_rois, negative_rois], axis=0)\n",
    "    N = tf.shape(negative_rois)[0]\n",
    "    P = tf.maximum(config.TRAIN_ROIS_PER_IMAGE - tf.shape(rois)[0], 0)\n",
    "    rois = tf.pad(rois, [(0, P), (0, 0)])\n",
    "    roi_gt_boxes = tf.pad(roi_gt_boxes, [(0, N + P), (0, 0)])\n",
    "    roi_gt_class_ids = tf.pad(roi_gt_class_ids, [(0, N + P)])\n",
    "    deltas = tf.pad(deltas, [(0, N + P), (0, 0)])\n",
    "    masks = tf.pad(masks, [[0, N + P], (0, 0), (0, 0)])\n",
    "\n",
    "    return rois, roi_gt_class_ids, deltas, masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(mode):\n",
    "    \n",
    "    base_map_size = 56\n",
    "    # Input shape\n",
    "    input_image = Input(shape=(224,224,3))\n",
    "    input_image_meta = KL.Input(shape=[config.IMAGE_META_SIZE],\n",
    "                                    name=\"input_image_meta\")\n",
    "    if mode == \"training\":\n",
    "        \n",
    "        active_class_ids = KL.Lambda(\n",
    "                lambda x: parse_image_meta_graph(x)[\"active_class_ids\"]\n",
    "                )(input_image_meta)\n",
    "        # RPN GT\n",
    "        input_rpn_match = KL.Input(\n",
    "            shape=[None, 1], name=\"input_rpn_match\", dtype=tf.int32)\n",
    "        input_rpn_bbox = KL.Input(\n",
    "            shape=[None, 2], name=\"input_rpn_bbox\", dtype=tf.float32)\n",
    "        # Detection GT (class IDs, bounding boxes, and masks)\n",
    "        # 1. GT Class IDs (zero padded)\n",
    "        input_gt_class_ids = KL.Input(\n",
    "            shape=[None], name=\"input_gt_class_ids\", dtype=tf.int32)\n",
    "        # 2. GT Boxes in pixels (zero padded)\n",
    "        # [batch, MAX_GT_INSTANCES, (y1, x1, y2, x2)] in image coordinates\n",
    "        input_gt_boxes = KL.Input(\n",
    "            shape=[None, 4], name=\"input_gt_boxes\", dtype=tf.float32)\n",
    "        # Normalize coordinates\n",
    "        gt_boxes = KL.Lambda(lambda x: norm_boxes_graph(\n",
    "            x, K.shape(input_image)[1:3]))(input_gt_boxes)\n",
    "        \n",
    "        input_gt_masks = KL.Input(\n",
    "            shape=[config.IMAGE_SHAPE[0], config.IMAGE_SHAPE[1], None],\n",
    "            name=\"input_gt_masks\", dtype=bool)\n",
    "\n",
    "#     elif mode == \"inference\":\n",
    "#         # Anchors in normalized coordinates\n",
    "#         input_anchors = KL.Input(shape=[None, 4], name=\"input_anchors\")\n",
    "\n",
    "    #resnet\n",
    "    res_model,C,C1,C2,C3,C4,C5 = resnet_graph(input_image, \"resnet50\", stage5=True)\n",
    "    \n",
    "#     for layer in res_model.layers:\n",
    "#         layer.trainable=False  \n",
    "        \n",
    "    # BilinearUpSampling C1 to 112 * 112\n",
    "#     C1 = BilinearUpSampling2D(target_size=(112, 112))(C1)\n",
    "    \n",
    "   \n",
    "    # Feature Pyramid Network \n",
    "    # get from https://github.com/matterport/Mask_RCNN/blob/master/model.py#L1792\n",
    "    # here using C1 and transform to P1\n",
    "    P5 = KL.Conv2D(256, (1, 1), name='fpn_c5p5')(C5)\n",
    "    P4 = KL.Add(name=\"fpn_p4add\")([\n",
    "        BilinearUpSampling2D(target_size=(14, 14))(P5),\n",
    "        KL.Conv2D(256, (1, 1), name='fpn_c4p4')(C4)])\n",
    "    P3 = KL.Add(name=\"fpn_p3add\")([\n",
    "        BilinearUpSampling2D(target_size=(28, 28))(P4),\n",
    "        KL.Conv2D(256, (1, 1), name='fpn_c3p3')(C3)])\n",
    "    P2 = KL.Add(name=\"fpn_p2add\")([\n",
    "        BilinearUpSampling2D(target_size=(56, 56))(P3),\n",
    "        KL.Conv2D(256, (1, 1), name='fpn_c2p2')(C2)])\n",
    "    # P6 is used for the 5th anchor scale in RPN. Generated by\n",
    "    # subsampling from P5 with stride of 2.\n",
    "#     P6 = KL.MaxPooling2D(pool_size=(1, 1), strides=2, name=\"fpn_p6\")(P5)\n",
    "\n",
    "   \n",
    "    # Bottom-up Path Augmentation\n",
    "    N2 = P2\n",
    "    N3 = KL.Add()([KL.Conv2D(256, (3, 3), strides=(2, 2), padding = \"SAME\")(P2), P3])\n",
    "    N4 = KL.Add()([KL.Conv2D(256, (3, 3), strides=(2, 2), padding = \"SAME\")(P3), P4])\n",
    "    N5 = KL.Add()([KL.Conv2D(256, (3, 3), strides=(2, 2), padding = \"SAME\")(P4), P5])\n",
    "#     N6 = KL.Add()([KL.Conv2D(256, (3, 3), strides=(2, 2), padding = \"SAME\")(P5), P6])\n",
    "    \n",
    "    \n",
    "    # Mapping to image size\n",
    "    \n",
    "    shared = KL.Add()([BilinearUpSampling2D(target_size=(224, 224))(P5),\n",
    "                 BilinearUpSampling2D(target_size=(224, 224))(P4),\n",
    "                 BilinearUpSampling2D(target_size=(224, 224))(P3),\n",
    "                 BilinearUpSampling2D(target_size=(224, 224))(P2)])\n",
    "    \n",
    "    print(\"Shared Layer :{}\".format(shared))\n",
    "    \n",
    "    \n",
    "    # generate anchors\n",
    "    box_size = [16, 32, 64, 128]\n",
    "    anchor_ratio = [0.5, 1, 2]\n",
    "\n",
    "    anchors = []\n",
    "\n",
    "    for i in range(len(box_size)):\n",
    "        boxes = generate_anchors(box_size[i], anchor_ratio, i)\n",
    "        anchors.append(tf.convert_to_tensor(boxes, tf.float32))\n",
    "        \n",
    "    anchors = tf.concat(anchors, axis=0)\n",
    "    print(\"Build Anchors : {}\".format(anchors))\n",
    "    \n",
    "    # First \n",
    "    croped = CroppingBoxLayer((16,16), anchors)(shared)\n",
    "    print(\"Cropped Layer1 : {}\".format(croped))\n",
    "    \n",
    "    x = KL.TimeDistributed(KL.Conv2D(1024, (16,16), padding = \"valid\"))(croped)\n",
    "    x = KL.TimeDistributed(KL.BatchNormalization(axis=-1))(x)\n",
    "    x = KL.Activation('relu')(x)\n",
    "    \n",
    "    x = KL.TimeDistributed(KL.Conv2D(1024, (1, 1), padding = \"valid\"))(x)\n",
    "    x = KL.TimeDistributed(KL.BatchNormalization(axis=-1))(x)\n",
    "    x = KL.Activation('relu')(x)    \n",
    "    \n",
    "    # predict of anchors foreground/background\n",
    "    object_conf = KL.TimeDistributed(KL.Conv2D(2, (1, 1), padding = \"valid\"))(x)\n",
    "    object_conf = KL.Lambda(lambda x: K.squeeze(K.squeeze(x, 3), 2),\n",
    "                       name=\"object_conf_squeeze\")(object_conf)\n",
    "    object_conf = KL.Lambda(lambda x: KL.Activation(\"softmax\")(x), name = \"object_confidence\")(object_conf)    \n",
    "    print(\"object_conf : {}\".format(object_conf))\n",
    "\n",
    "    \n",
    "    # predict of box center offset \n",
    "    box_offset = KL.TimeDistributed(KL.Conv2D(2, (1, 1), padding = \"valid\"))(x)\n",
    "    box_offset = KL.Lambda(lambda x: K.squeeze(K.squeeze(x, 3), 2),\n",
    "                       name=\"box_offset_squeeze\")(box_offset)\n",
    "    box_offset = KL.Lambda(lambda x: KL.Activation(\"linear\")(x), name = \"box_offset\")(box_offset)\n",
    "    print(\"box_offset : {}\".format(box_offset))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # refine boxes coordinate by center offset and crop again\n",
    "    refine_croped, rois, target_class_ids, target_bbox, target_mask = RefineAndCropLayer(config, anchors, shared)([box_offset, input_gt_class_ids, gt_boxes, input_gt_masks])\n",
    "    \n",
    "    print(\"RefinegBoxLayer : {}\".format(refine_croped))\n",
    "#     print(\"RefinegBoxLayer boxes : {}\".format(boxes))\n",
    "    \n",
    "#     rois, target_class_ids, target_bbox, target_mask =\\\n",
    "#             DetectionTargetLayer(config, name=\"proposal_targets\")([\n",
    "#                 boxes, input_gt_class_ids, gt_boxes, input_gt_masks])\n",
    "    \n",
    "    print(\"rois : {}\".format(rois))\n",
    "    print(\"target_class_ids : {}\".format(target_class_ids))\n",
    "    print(\"target_bbox : {}\".format(target_bbox))\n",
    "    print(\"target_mask : {}\".format(target_mask))\n",
    "    \n",
    "\n",
    "    x = KL.TimeDistributed(KL.Conv2D(1024, (16,16), padding = \"valid\"))(refine_croped)\n",
    "    x = KL.TimeDistributed(KL.BatchNormalization(axis=-1))(x)\n",
    "    x = KL.Activation('relu')(x)\n",
    "    \n",
    "    x = KL.TimeDistributed(KL.Conv2D(1024, (1, 1), padding = \"valid\"))(x)\n",
    "    x = KL.TimeDistributed(KL.BatchNormalization(axis=-1))(x)\n",
    "    x = KL.Activation('relu')(x)    \n",
    "    \n",
    "    \n",
    "    x = KL.Lambda(lambda x: K.squeeze(K.squeeze(x, 3), 2),\n",
    "                       name=\"pool_squeeze\")(x)\n",
    "\n",
    "    object_cls = KL.TimeDistributed(KL.Dense(80))(x)\n",
    "    object_cls = KL.Lambda(lambda x: KL.Activation(\"softmax\")(x), name = \"object_classification\")(object_cls)\n",
    "    print(\"object_cls : {}\".format(object_cls))\n",
    "\n",
    "    # [batch, boxes, num_classes * (dy, dx, log(dh), log(dw))]\n",
    "    x = KL.TimeDistributed(KL.Dense(80 * 4, activation='linear'))(x)\n",
    "    # Reshape to [batch, boxes, num_classes, (dy, dx, log(dh), log(dw))]\n",
    "    print(x)\n",
    "    s = K.int_shape(x)\n",
    "    print(s[1])\n",
    "    box_reg = KL.Reshape((s[1], 80, 4), name=\"box_reg\")(x)\n",
    "    print(\"box_reg : {}\".format(box_reg))\n",
    "    \n",
    "\n",
    "    \n",
    "#     output = KL.concatenate([object_conf, box_reg, object_cls])\n",
    "#     print(\"output : {}\".format(output))\n",
    "    \n",
    "    if mode == \"training\":\n",
    "        \n",
    "        # Losses\n",
    "        rpn_class_loss = KL.Lambda(lambda x: confidence_loss(*x), name=\"rpn_class_loss\")(\n",
    "            [input_rpn_match, object_conf])\n",
    "        rpn_bbox_loss = KL.Lambda(lambda x: box_reg_loss(config, *x), name=\"rpn_bbox_loss\")(\n",
    "            [input_rpn_bbox, input_rpn_match, box_offset])\n",
    "        # classify loss\n",
    "        class_loss = KL.Lambda(lambda x: mrcnn_class_loss_graph(*x), name=\"mrcnn_class_loss\")(\n",
    "                [target_class_ids, object_cls, active_class_ids])\n",
    "        bbox_loss = KL.Lambda(lambda x: mrcnn_bbox_loss_graph(*x), name=\"mrcnn_bbox_loss\")(\n",
    "                [target_bbox, target_class_ids, box_reg])\n",
    "        \n",
    "        inputs = [input_image, input_image_meta,\n",
    "                  input_rpn_match, input_rpn_bbox,\n",
    "                  input_gt_class_ids, input_gt_boxes, input_gt_masks]\n",
    "        \n",
    "#         outputs = [object_conf, box_offset,\n",
    "#                   rpn_class_loss, rpn_bbox_loss, class_loss]\n",
    "        \n",
    "        outputs = [object_conf, box_offset,\n",
    "                  object_cls, box_reg,\n",
    "                  rpn_class_loss, rpn_bbox_loss, class_loss, bbox_loss]\n",
    "\n",
    "    \n",
    "        model = KM.Model(inputs, outputs)\n",
    "        \n",
    "    else:\n",
    "        inputs = [input_image]\n",
    "        \n",
    "        outputs = [object_conf]\n",
    "        \n",
    "        model = KM.Model(inputs, outputs)\n",
    "        \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_image : Tensor(\"input_1:0\", shape=(?, 224, 224, 3), dtype=float32) \n",
      "C1 : Tensor(\"max_pooling2d_1/MaxPool:0\", shape=(?, 56, 56, 64), dtype=float32) \n",
      "C2 : Tensor(\"res2c_out/Relu:0\", shape=(?, 56, 56, 256), dtype=float32) \n",
      "C3 : Tensor(\"res3d_out/Relu:0\", shape=(?, 28, 28, 512), dtype=float32) \n",
      "C4 : Tensor(\"res4f_out/Relu:0\", shape=(?, 14, 14, 1024), dtype=float32) \n",
      "C5 : Tensor(\"res5c_out/Relu:0\", shape=(?, 7, 7, 2048), dtype=float32) \n",
      "Shared Layer :Tensor(\"add_20/add_2:0\", shape=(?, 224, 224, 256), dtype=float32)\n",
      "Build Anchors : Tensor(\"concat:0\", shape=(12495, 4), dtype=float32)\n",
      "CroppingBoxLayer anchors :Tensor(\"concat:0\", shape=(12495, 4), dtype=float32)\n",
      "CroppingBoxLayer indice :Tensor(\"cropping_box_layer_1/Cast_1:0\", shape=(12495,), dtype=int32)\n",
      "Cropped Layer1 : Tensor(\"cropping_box_layer_1/ExpandDims:0\", shape=(1, 12495, 16, 16, 256), dtype=float32)\n",
      "object_conf : Tensor(\"object_confidence/activation_36/truediv:0\", shape=(1, ?, 2), dtype=float32)\n",
      "box_offset : Tensor(\"box_offset/activation_38/Identity:0\", shape=(1, ?, 2), dtype=float32)\n",
      "RefineAndCropLayer input boxes: Tensor(\"refine_and_crop_layer_1/ExpandDims:0\", shape=(1, 12495, 4), dtype=float32)\n",
      "RefineAndCropLayer refined proposals: Tensor(\"refine_and_crop_layer_1/ExpandDims:0\", shape=(1, 12495, 4), dtype=float32)\n",
      "Tensor(\"refine_and_crop_layer_1/rois:0\", shape=(1, ?, ?), dtype=float32)\n",
      "RefineAndCropLayer rois :Tensor(\"refine_and_crop_layer_1/Squeeze_1:0\", shape=(?, ?), dtype=float32)\n",
      "RefineAndCropLayer indice :Tensor(\"refine_and_crop_layer_1/Cast_8:0\", shape=(?,), dtype=int32)\n",
      "RefineAndCropLayer cropped :Tensor(\"refine_and_crop_layer_1/ExpandDims_4:0\", shape=(1, ?, 16, 16, 256), dtype=float32)\n",
      "RefinegBoxLayer : Tensor(\"refine_and_crop_layer_1/ExpandDims_4:0\", shape=(1, ?, 16, 16, 256), dtype=float32)\n",
      "rois : Tensor(\"refine_and_crop_layer_1/Squeeze_1:0\", shape=(?, ?), dtype=float32)\n",
      "target_class_ids : Tensor(\"refine_and_crop_layer_1/target_class_ids:0\", shape=(1, ?), dtype=int32)\n",
      "target_bbox : Tensor(\"refine_and_crop_layer_1/target_bbox:0\", shape=(1, ?, ?), dtype=float32)\n",
      "target_mask : Tensor(\"refine_and_crop_layer_1/target_mask:0\", shape=(1, ?, ?, ?), dtype=float32)\n",
      "object_cls : Tensor(\"object_classification/activation_42/truediv:0\", shape=(?, 32, 80), dtype=float32)\n",
      "Tensor(\"time_distributed_12/Reshape_1:0\", shape=(?, 32, 320), dtype=float32)\n",
      "32\n",
      "box_reg : Tensor(\"box_reg/Reshape:0\", shape=(?, 32, 80, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "Gmodel = model(\"training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights_path = 'keras_resnet50_weight.hdf5'\n",
    "# weights_path = 'VOC_model.h5'\n",
    "# Gmodel.load_weights(weights_path,by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPadding2D (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        zero_padding2d_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 64)   0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 56, 56, 64)   4160        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 56, 56, 256)  16640       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 56, 56, 256)  1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 56, 56, 256)  0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_out (Activation)          (None, 56, 56, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 56, 56, 64)   16448       res2a_out[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 56, 56, 256)  0           bn2b_branch2c[0][0]              \n",
      "                                                                 res2a_out[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2b_out (Activation)          (None, 56, 56, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 56, 56, 64)   16448       res2b_out[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 56, 56, 256)  0           bn2c_branch2c[0][0]              \n",
      "                                                                 res2b_out[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2c_out (Activation)          (None, 56, 56, 256)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       res2c_out[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      res2c_out[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res3a_out (Activation)          (None, 28, 28, 512)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       res3a_out[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n",
      "                                                                 res3a_out[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res3b_out (Activation)          (None, 28, 28, 512)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       res3b_out[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n",
      "                                                                 res3b_out[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res3c_out (Activation)          (None, 28, 28, 512)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       res3c_out[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n",
      "                                                                 res3c_out[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res3d_out (Activation)          (None, 28, 28, 512)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      res3d_out[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      res3d_out[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res4a_out (Activation)          (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      res4a_out[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n",
      "                                                                 res4a_out[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res4b_out (Activation)          (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      res4b_out[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n",
      "                                                                 res4b_out[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res4c_out (Activation)          (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      res4c_out[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n",
      "                                                                 res4c_out[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res4d_out (Activation)          (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      res4d_out[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n",
      "                                                                 res4d_out[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res4e_out (Activation)          (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      res4e_out[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n",
      "                                                                 res4e_out[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res4f_out (Activation)          (None, 14, 14, 1024) 0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      res4f_out[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     res4f_out[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res5a_out (Activation)          (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     res5a_out[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n",
      "                                                                 res5a_out[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res5b_out (Activation)          (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     res5b_out[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 7, 7, 2048)   0           bn5c_branch2c[0][0]              \n",
      "                                                                 res5b_out[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res5c_out (Activation)          (None, 7, 7, 2048)   0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "fpn_c5p5 (Conv2D)               (None, 7, 7, 256)    524544      res5c_out[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bilinear_up_sampling2d_1 (Bilin (None, 14, 14, 256)  0           fpn_c5p5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "fpn_c4p4 (Conv2D)               (None, 14, 14, 256)  262400      res4f_out[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "fpn_p4add (Add)                 (None, 14, 14, 256)  0           bilinear_up_sampling2d_1[0][0]   \n",
      "                                                                 fpn_c4p4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bilinear_up_sampling2d_2 (Bilin (None, 28, 28, 256)  0           fpn_p4add[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "fpn_c3p3 (Conv2D)               (None, 28, 28, 256)  131328      res3d_out[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "fpn_p3add (Add)                 (None, 28, 28, 256)  0           bilinear_up_sampling2d_2[0][0]   \n",
      "                                                                 fpn_c3p3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bilinear_up_sampling2d_3 (Bilin (None, 56, 56, 256)  0           fpn_p3add[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "fpn_c2p2 (Conv2D)               (None, 56, 56, 256)  65792       res2c_out[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "fpn_p2add (Add)                 (None, 56, 56, 256)  0           bilinear_up_sampling2d_3[0][0]   \n",
      "                                                                 fpn_c2p2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bilinear_up_sampling2d_4 (Bilin (None, 224, 224, 256 0           fpn_c5p5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bilinear_up_sampling2d_5 (Bilin (None, 224, 224, 256 0           fpn_p4add[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bilinear_up_sampling2d_6 (Bilin (None, 224, 224, 256 0           fpn_p3add[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bilinear_up_sampling2d_7 (Bilin (None, 224, 224, 256 0           fpn_p2add[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, 224, 224, 256 0           bilinear_up_sampling2d_4[0][0]   \n",
      "                                                                 bilinear_up_sampling2d_5[0][0]   \n",
      "                                                                 bilinear_up_sampling2d_6[0][0]   \n",
      "                                                                 bilinear_up_sampling2d_7[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "cropping_box_layer_1 (CroppingB (1, 12495, 16, 16, 2 0           add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (1, 12495, 1, 1, 256 16777472    cropping_box_layer_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistrib (1, 12495, 1, 1, 256 1024        time_distributed_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (1, 12495, 1, 1, 256 0           time_distributed_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_3 (TimeDistrib (1, 12495, 1, 1, 102 263168      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_4 (TimeDistrib (1, 12495, 1, 1, 102 4096        time_distributed_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (1, 12495, 1, 1, 102 0           time_distributed_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_6 (TimeDistrib (1, 12495, 1, 1, 2)  2050        activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "box_offset_squeeze (Lambda)     (1, 12495, 2)        0           time_distributed_6[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "input_gt_boxes (InputLayer)     (None, None, 4)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "box_offset (Lambda)             (1, 12495, 2)        0           box_offset_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "input_gt_class_ids (InputLayer) (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, None, 4)      0           input_gt_boxes[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "input_gt_masks (InputLayer)     (None, 224, 224, Non 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "refine_and_crop_layer_1 (Refine [(None, 32, 16, 16,  0           box_offset[0][0]                 \n",
      "                                                                 input_gt_class_ids[0][0]         \n",
      "                                                                 lambda_2[0][0]                   \n",
      "                                                                 input_gt_masks[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_7 (TimeDistrib (None, 32, 1, 1, 256 16777472    refine_and_crop_layer_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_8 (TimeDistrib (None, 32, 1, 1, 256 1024        time_distributed_7[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 32, 1, 1, 256 0           time_distributed_8[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_9 (TimeDistrib (None, 32, 1, 1, 102 263168      activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_10 (TimeDistri (None, 32, 1, 1, 102 4096        time_distributed_9[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 32, 1, 1, 102 0           time_distributed_10[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_5 (TimeDistrib (1, 12495, 1, 1, 2)  2050        activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "pool_squeeze (Lambda)           (None, 32, 1024)     0           activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "object_conf_squeeze (Lambda)    (1, 12495, 2)        0           time_distributed_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_11 (TimeDistri (None, 32, 80)       82000       pool_squeeze[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_12 (TimeDistri (None, 32, 320)      328000      pool_squeeze[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "input_image_meta (InputLayer)   (None, 93)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "object_confidence (Lambda)      (1, 12495, 2)        0           object_conf_squeeze[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "object_classification (Lambda)  (None, 32, 80)       0           time_distributed_11[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "box_reg (Reshape)               (None, 32, 80, 4)    0           time_distributed_12[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "input_rpn_match (InputLayer)    (None, None, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_rpn_bbox (InputLayer)     (None, None, 2)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 81)           0           input_image_meta[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "rpn_class_loss (Lambda)         ()                   0           input_rpn_match[0][0]            \n",
      "                                                                 object_confidence[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "rpn_bbox_loss (Lambda)          ()                   0           input_rpn_bbox[0][0]             \n",
      "                                                                 input_rpn_match[0][0]            \n",
      "                                                                 box_offset[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "mrcnn_class_loss (Lambda)       ()                   0           refine_and_crop_layer_1[0][2]    \n",
      "                                                                 object_classification[0][0]      \n",
      "                                                                 lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "mrcnn_bbox_loss (Lambda)        None                 0           refine_and_crop_layer_1[0][3]    \n",
      "                                                                 refine_and_crop_layer_1[0][2]    \n",
      "                                                                 box_reg[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 59,077,396\n",
      "Trainable params: 59,019,156\n",
      "Non-trainable params: 58,240\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Gmodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD,Adam\n",
    "sgd = SGD(lr = config.LEARNING_RATE, decay=1e-6, momentum=config.LEARNING_MOMENTUM, nesterov=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gmodel.compile(sgd,confidence_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Losses\n",
    "# First, clear previously set losses to avoid duplication\n",
    "Gmodel._losses = []\n",
    "Gmodel._per_input_losses = {}\n",
    "# loss_names = [\n",
    "#     \"rpn_class_loss\",  \"rpn_bbox_loss\", \"mrcnn_class_loss\"]\n",
    "loss_names = [\n",
    "    \"rpn_class_loss\",  \"rpn_bbox_loss\",\n",
    "    \"mrcnn_class_loss\", \"mrcnn_bbox_loss\"]\n",
    "\n",
    "for name in loss_names:\n",
    "    layer = Gmodel.get_layer(name)\n",
    "    if layer.output in Gmodel.losses:\n",
    "        continue\n",
    "    loss = (\n",
    "        tf.reduce_mean(layer.output, keep_dims=True))\n",
    "    Gmodel.add_loss(loss)\n",
    "\n",
    "# # Add L2 Regularization\n",
    "# # Skip gamma and beta weights of batch normalization layers.\n",
    "# reg_losses = [\n",
    "#     keras.regularizers.l2(config.WEIGHT_DECAY)(w) / tf.cast(tf.size(w), tf.float32)\n",
    "#     for w in Gmodel.trainable_weights\n",
    "#     if 'gamma' not in w.name and 'beta' not in w.name]\n",
    "# Gmodel.add_loss(tf.add_n(reg_losses))\n",
    "\n",
    "\n",
    "Gmodel.compile(\n",
    "            optimizer=sgd,\n",
    "            loss=[None] * len(Gmodel.outputs))\n",
    "\n",
    "# Add metrics for losses\n",
    "for name in loss_names:\n",
    "    if name in Gmodel.metrics_names:\n",
    "        continue\n",
    "    layer = Gmodel.get_layer(name)\n",
    "    Gmodel.metrics_names.append(name)\n",
    "    loss = (\n",
    "        tf.reduce_mean(layer.output, keep_dims=True))\n",
    "    Gmodel.metrics_tensors.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'Mean:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'Mean_1:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'Mean_2:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'Mean_3:0' shape=<unknown> dtype=float32>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Gmodel.losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import scipy.misc\n",
    "from scipy import ndimage\n",
    "from utils.Data_Generator import build_rpn_targets\n",
    "\n",
    "# change RGB to gray scale\n",
    "def rgb2gray(rgb):\n",
    "    return np.dot(rgb[...,:3], [0.299, 0.587, 0.114])\n",
    "def mold_image(images, config):\n",
    "    \"\"\"Takes RGB images with 0-255 values and subtraces\n",
    "    the mean pixel and converts it to float. Expects image\n",
    "    colors in RGB order.\n",
    "    \"\"\"\n",
    "    return images.astype(np.float32) - config.MEAN_PIXEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(93,)\n",
      "(12495,)\n",
      "(12495, 2)\n",
      "(12495,)\n",
      "\u001b[34m\"Train Tiem : 0  \"\u001b[0m\n",
      "\u001b[34m\"Train Tiem : 5  \"\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:96: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 99s 99s/step - loss: 6.2427 - rpn_class_loss: 0.6931 - rpn_bbox_loss: 1.1675 - mrcnn_class_loss: 4.3820 - mrcnn_bbox_loss: 0.0000e+00\n",
      "(93,)\n",
      "(12495,)\n",
      "(12495, 2)\n",
      "(12495,)\n",
      "\u001b[34m\"Train Tiem : 1  \"\u001b[0m\n",
      "\u001b[34m\"Train Tiem : 5  \"\u001b[0m\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 84s 84s/step - loss: 6.2243 - rpn_class_loss: 0.6927 - rpn_bbox_loss: 1.1496 - mrcnn_class_loss: 4.3820 - mrcnn_bbox_loss: 0.0000e+00\n",
      "(93,)\n",
      "(12495,)\n",
      "(12495, 2)\n",
      "(12495,)\n",
      "\u001b[34m\"Train Tiem : 2  \"\u001b[0m\n",
      "\u001b[34m\"Train Tiem : 5  \"\u001b[0m\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 83s 83s/step - loss: 6.2235 - rpn_class_loss: 0.6920 - rpn_bbox_loss: 1.1495 - mrcnn_class_loss: 4.3820 - mrcnn_bbox_loss: 0.0000e+00\n",
      "(93,)\n",
      "(12495,)\n",
      "(12495, 2)\n",
      "(12495,)\n",
      "\u001b[34m\"Train Tiem : 3  \"\u001b[0m\n",
      "\u001b[34m\"Train Tiem : 5  \"\u001b[0m\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 83s 83s/step - loss: 6.2400 - rpn_class_loss: 0.6911 - rpn_bbox_loss: 1.1669 - mrcnn_class_loss: 4.3820 - mrcnn_bbox_loss: 0.0000e+00\n",
      "(93,)\n",
      "(12495,)\n",
      "(12495, 2)\n",
      "(12495,)\n",
      "\u001b[34m\"Train Tiem : 4  \"\u001b[0m\n",
      "\u001b[34m\"Train Tiem : 5  \"\u001b[0m\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 84s 84s/step - loss: 6.2387 - rpn_class_loss: 0.6901 - rpn_bbox_loss: 1.1665 - mrcnn_class_loss: 4.3820 - mrcnn_bbox_loss: 0.0000e+00\n",
      "(93,)\n",
      "(12495,)\n",
      "(12495, 2)\n",
      "(12495,)\n",
      "\u001b[34m\"Train Tiem : 5  \"\u001b[0m\n",
      "\u001b[34m\"Train Tiem : 5  \"\u001b[0m\n",
      "Epoch 1/1\n"
     ]
    }
   ],
   "source": [
    "for itera in range(0,100):\n",
    "#     K.clear_session()\n",
    "#     image_id = random.randint(0,5)\n",
    "    image_id = 5\n",
    "    image, image_meta, gt_class_ids,gt_boxes, gt_masks, gt_all_masks = \\\n",
    "            load_image_gt(dataset_train, config, image_id, augment=True,\n",
    "                      use_mini_mask=config.USE_MINI_MASK,use_background=True)\n",
    "    print(image_meta.shape)\n",
    "    box_size = [16, 32, 64, 128]\n",
    "    anchor_ratio = [0.5, 1, 2]\n",
    "\n",
    "    anchors = []\n",
    "\n",
    "    for i in range(len(box_size)):\n",
    "        anchors.append(generate_anchors(box_size[i], anchor_ratio, i))\n",
    "\n",
    "    anchors = np.concatenate(anchors, axis=0)\n",
    "    \n",
    "    # RPN Targets\n",
    "    rpn_match, rpn_bbox = build_rpn_targets(image.shape, anchors,\n",
    "                                            gt_class_ids, gt_boxes, config)\n",
    "    print(rpn_bbox.shape)\n",
    "\n",
    "    batch_image_meta = np.zeros(\n",
    "        (1,) + image_meta.shape, dtype=image_meta.dtype)\n",
    "    batch_rpn_match = np.zeros(\n",
    "        [1, anchors.shape[0], 1], dtype=rpn_match.dtype)\n",
    "    batch_rpn_bbox = np.zeros(\n",
    "        [1, 12495, 2], dtype=rpn_bbox.dtype)\n",
    "    batch_images = np.zeros(\n",
    "        (1,) + image.shape, dtype=np.float32)\n",
    "    batch_gt_class_ids = np.zeros(\n",
    "        (1, 12495), dtype=np.int32)\n",
    "    batch_gt_boxes = np.zeros(\n",
    "        [1, 12495, 4], dtype=np.int32)\n",
    "    batch_gt_masks = np.zeros(\n",
    "        (1, gt_masks.shape[0], gt_masks.shape[1],\n",
    "         config.MAX_GT_INSTANCES), dtype=gt_masks.dtype)\n",
    "\n",
    "\n",
    "    batch_image_meta[0] = image_meta\n",
    "    batch_images[0] = mold_image(image.astype(np.float32), config)\n",
    "    batch_rpn_match[0] = rpn_match[:, np.newaxis]\n",
    "    batch_rpn_bbox[0] = rpn_bbox\n",
    "    batch_gt_class_ids[0, :gt_class_ids.shape[0]] = gt_class_ids\n",
    "    batch_gt_boxes[0, :gt_boxes.shape[0]] = gt_boxes\n",
    "    batch_gt_masks[0, :, :, :gt_masks.shape[-1]] = gt_masks\n",
    "#     batch_rpn_bbox = np.concatenate((batch_rpn_match, batch_rpn_bbox))\n",
    "    \n",
    "    print(rpn_match.shape)\n",
    "    \n",
    "    #     model.fit(x,[y,y,y,y,y,y])\n",
    "    print(\"\\x1b[34m\\\"Train Tiem : {}  \\\"\\x1b[0m\".format(itera))\n",
    "    print(\"\\x1b[34m\\\"Train Tiem : {}  \\\"\\x1b[0m\".format(image_id))\n",
    "#     model.fit(x,[y,y,y,y,y,z,z,z,z,z,M,M,M,M,M])\n",
    "#     model.fit(x,[y,y,y,y,y,y])\n",
    "#     model.fit(x,[E,E,E,E,E,E])\n",
    "    Gmodel.fit([batch_images, batch_image_meta,\n",
    "                batch_rpn_match, batch_rpn_bbox,\n",
    "                batch_gt_class_ids, batch_gt_boxes, batch_gt_masks],[])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gmodel.save_weights(\"ALL_MODEL.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "f, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2,2 , sharey=False)\n",
    "# class_id = 38\n",
    "Back = B[0,:,:,0]\n",
    "# # Back = Back / 5\n",
    "Back[Back<0.5] = 0\n",
    "\n",
    "Edge = E[0,:,:,0]\n",
    "# # E[E < 0.02] = 0.0\n",
    "# tmp = Back - 5*Edge\n",
    "# tmp *= 1/ tmp.max()\n",
    "# tmp[Back<0.5] = 0\n",
    "# tmp[tmp<0] = 0\n",
    "result1 = np.argmax(np.squeeze(B), axis=-1).astype(np.uint8)\n",
    "result2 = np.argmax(np.squeeze(batch_background), axis=-1).astype(np.uint8)\n",
    "ax1.imshow(Back)\n",
    "ax2.imshow(Edge)\n",
    "ax3.imshow(result1)\n",
    "\n",
    "ax4.imshow(batch_edge[0,:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_id = 5\n",
    "image, gt_class_ids,gt_boxes, gt_masks, gt_all_masks = \\\n",
    "        load_image_gt(dataset_train, config, image_id, augment=True,\n",
    "                  use_mini_mask=config.USE_MINI_MASK,use_background=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "plt.imshow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3,  3,  3,  8,  8, 10, 10, 10,  1,  3,  3, 10, 10, 10,  3], dtype=int32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_class_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[101,   0, 116,  14],\n",
       "       [100,  14, 114,  37],\n",
       "       [101, 159, 107, 176],\n",
       "       [ 70,  46, 137, 146],\n",
       "       [ 95, 178, 125, 222],\n",
       "       [ 72, 170,  77, 173],\n",
       "       [ 67, 205,  74, 209],\n",
       "       [ 89, 177,  92, 179],\n",
       "       [ 96,  33, 146,  54],\n",
       "       [101, 142, 106, 150],\n",
       "       [100, 168, 107, 187],\n",
       "       [ 85, 157,  90, 159],\n",
       "       [ 89, 173,  92, 176],\n",
       "       [ 89, 151,  93, 155],\n",
       "       [ 99, 150, 107, 168]], dtype=int32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<utils.shape.ShapesConfig at 0x7f19edc09940>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-c594890db870>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrpn_match\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrpn_bbox\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_rpn_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manchors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgt_class_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_boxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "rpn_match, rpn_bbox = build_rpn_targets(image.shape, anchors,gt_class_ids, gt_boxes, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -11.3137085 ,   -5.65685425,   11.3137085 ,    5.65685425],\n",
       "       [ -22.627417  ,  -11.3137085 ,   22.627417  ,   11.3137085 ],\n",
       "       [ -45.254834  ,  -22.627417  ,   45.254834  ,   22.627417  ],\n",
       "       ..., \n",
       "       [ 200.372583  ,  177.745166  ,  245.627417  ,  268.254834  ],\n",
       "       [ 177.745166  ,  132.49033201,  268.254834  ,  313.50966799],\n",
       "       [ 132.49033201,   41.98066402,  313.50966799,  404.01933598]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_rpn_targets(image.shape, anchors,gt_class_ids, gt_boxes, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_overlaps(boxes1, boxes2):\n",
    "    \"\"\"Computes IoU overlaps between two sets of boxes.\n",
    "    boxes1, boxes2: [N, (y1, x1, y2, x2)].\n",
    "    For better performance, pass the largest set first and the smaller second.\n",
    "    \"\"\"\n",
    "    # Areas of anchors and GT boxes\n",
    "    area1 = (boxes1[:, 2] - boxes1[:, 0]) * (boxes1[:, 3] - boxes1[:, 1])\n",
    "    area2 = (boxes2[:, 2] - boxes2[:, 0]) * (boxes2[:, 3] - boxes2[:, 1])\n",
    "\n",
    "    # Compute overlaps to generate matrix [boxes1 count, boxes2 count]\n",
    "    # Each cell contains the IoU value.\n",
    "    overlaps = np.zeros((boxes1.shape[0], boxes2.shape[0]))\n",
    "    for i in range(overlaps.shape[1]):\n",
    "        box2 = boxes2[i]\n",
    "        overlaps[:, i] = compute_iou(box2, boxes1, area2[i], area1)\n",
    "    return overlaps\n",
    "def compute_iou(box, boxes, box_area, boxes_area):\n",
    "    \"\"\"Calculates IoU of the given box with the array of the given boxes.\n",
    "    box: 1D vector [y1, x1, y2, x2]\n",
    "    boxes: [boxes_count, (y1, x1, y2, x2)]\n",
    "    box_area: float. the area of 'box'\n",
    "    boxes_area: array of length boxes_count.\n",
    "    Note: the areas are passed in rather than calculated here for\n",
    "          efficency. Calculate once in the caller to avoid duplicate work.\n",
    "    \"\"\"\n",
    "    # Calculate intersection areas\n",
    "    y1 = np.maximum(box[0], boxes[:, 0])\n",
    "    y2 = np.minimum(box[2], boxes[:, 2])\n",
    "    x1 = np.maximum(box[1], boxes[:, 1])\n",
    "    x2 = np.minimum(box[3], boxes[:, 3])\n",
    "    intersection = np.maximum(x2 - x1, 0) * np.maximum(y2 - y1, 0)\n",
    "    union = box_area + boxes_area[:] - intersection[:]\n",
    "    iou = intersection / union\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_id = 5\n",
    "image, gt_class_ids,gt_boxes, gt_masks, gt_all_masks = \\\n",
    "        load_image_gt(dataset_train, config, image_id, augment=True,\n",
    "                  use_mini_mask=config.USE_MINI_MASK,use_background=True)\n",
    "\n",
    "box_size = [16, 32, 64, 128]\n",
    "anchor_ratio = [0.5, 1, 2]\n",
    "\n",
    "anchors = []\n",
    "\n",
    "for i in range(len(box_size)):\n",
    "    anchors.append(generate_anchors(box_size[i], anchor_ratio, i))\n",
    "\n",
    "anchors = np.concatenate(anchors, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12495,)\n"
     ]
    }
   ],
   "source": [
    "# RPN Match: 1 = positive anchor, -1 = negative anchor, 0 = neutral\n",
    "rpn_match = np.zeros([anchors.shape[0]], dtype=np.int32)\n",
    "rpn_match_class = np.zeros([anchors.shape[0]], dtype=np.int32)\n",
    "# RPN bounding boxes: [max anchors per image, (dy, dx, log(dh), log(dw))]\n",
    "#     rpn_bbox = np.zeros((config.RPN_TRAIN_ANCHORS_PER_IMAGE, 4))\n",
    "rpn_bbox = np.zeros((12495, 4))\n",
    "# Handle COCO crowds\n",
    "# A crowd box in COCO is a bounding box around several instances. Exclude\n",
    "# them from training. A crowd box is given a negative class ID.\n",
    "crowd_ix = np.where(gt_class_ids < 0)[0]\n",
    "if crowd_ix.shape[0] > 0:\n",
    "    # Filter out crowds from ground truth class IDs and boxes\n",
    "    non_crowd_ix = np.where(gt_class_ids > 0)[0]\n",
    "    crowd_boxes = gt_boxes[crowd_ix]\n",
    "    gt_class_ids = gt_class_ids[non_crowd_ix]\n",
    "    gt_boxes = gt_boxes[non_crowd_ix]\n",
    "    # Compute overlaps with crowd boxes [anchors, crowds]\n",
    "    crowd_overlaps = compute_overlaps(anchors, crowd_boxes)\n",
    "    crowd_iou_max = np.amax(crowd_overlaps, axis=1)\n",
    "    no_crowd_bool = (crowd_iou_max < 0.001)\n",
    "else:\n",
    "    # All anchors don't intersect a crowd\n",
    "    no_crowd_bool = np.ones([anchors.shape[0]], dtype=bool)\n",
    "\n",
    "# Compute overlaps [num_anchors, num_gt_boxes]\n",
    "overlaps = compute_overlaps(anchors, gt_boxes)\n",
    "\n",
    "# Match anchors to GT Boxes\n",
    "# If an anchor overlaps a GT box with IoU >= 0.7 then it's positive.\n",
    "# If an anchor overlaps a GT box with IoU < 0.3 then it's negative.\n",
    "# Neutral anchors are those that don't match the conditions above,\n",
    "# and they don't influence the loss function.\n",
    "# However, don't keep any GT box unmatched (rare, but happens). Instead,\n",
    "# match it to the closest anchor (even if its max IoU is < 0.3).\n",
    "#\n",
    "# 1. Set negative anchors first. They get overwritten below if a GT box is\n",
    "# matched to them. Skip boxes in crowd areas.\n",
    "anchor_iou_argmax = np.argmax(overlaps, axis=1)\n",
    "anchor_iou_max = overlaps[np.arange(overlaps.shape[0]), anchor_iou_argmax]\n",
    "print(anchor_iou_max.shape)\n",
    "rpn_match[(anchor_iou_max < 0.3) & (no_crowd_bool)] = -1\n",
    "# 2. Set an anchor for each GT box (regardless of IoU value).\n",
    "# TODO: If multiple anchors have the same IoU match all of them\n",
    "gt_iou_argmax = np.argmax(overlaps, axis=0)\n",
    "rpn_match[gt_iou_argmax] = 1\n",
    "# 3. Set anchors with high overlap as positive.\n",
    "rpn_match[anchor_iou_max >= 0.7] = 1\n",
    "\n",
    "rpn_match_class[gt_iou_argmax] = gt_class_ids[np.arange(gt_iou_argmax.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "rpn_match_class[gt_iou_argmax] = gt_class_ids[np.arange(gt_iou_argmax.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10, 10, 10, 10, 10, 10,  3,  3,  3,  3,  3,  3,  8,  1,  8], dtype=int32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rpn_match_class[rpn_match_class>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3,  3,  3,  8,  8, 10, 10, 10,  1,  3,  3, 10, 10, 10,  3], dtype=int32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_class_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
